# Feature-Selection_for_predictive_model_with_python
Feature selection helps you in the mission to create an accurate predictive model. It helps you by choosing features that will give you as good or better accuracy while requiring less data.  The key benefits of performing feature selection on the data are:  Reduces Overfitting: Less redundant data means less chance to make decisions based on noise. Improves Accuracy: Less misleading data means improvements in modeling accuracy. Reduces Training Time: Less data means algorithms train faster. Improves Interpretability: Less complexity of a model makes it easier to interpret. In some cases, a domain expert can indicate which features have the most predictive power and which features can be ignored. When this is not possible (and in some cases even when it is possible), we can employ algorithmic feature selection to automatically quantify the importance of features so that a threshold can be used to identify the best features for a particular application.  Broadly speaking there are three general classes of feature selection algorithms:  Filter methods Wrapper methods Embedded methods
